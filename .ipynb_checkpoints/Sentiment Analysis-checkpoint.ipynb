{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using data from IMDB, Yelp, and Amazon reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "imdb_data = pd.read_csv('imdb_labelled.txt', sep='.  ')\n",
    "imdb_data.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very little music or anything to speak of</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Not sure who was more lost - the flat characte...      0\n",
       "1  Attempting artiness with black & white and cle...      0\n",
       "2          Very little music or anything to speak of      0\n",
       "3  The best scene in the movie was when Gerardo i...      1\n",
       "4  The rest of the movie lacks art, charm, meanin...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazon_data = pd.read_csv('amazon_cells_labelled.txt', sep='\\t')\n",
    "amazon_data.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_data = pd.read_csv('yelp_labelled.txt', sep='\\t')\n",
    "yelp_data.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                        Good case, Excellent value.      1\n",
       "1                             Great for the jawbone.      1\n",
       "2  Tied to charger for conversations lasting more...      0\n",
       "3                                  The mic is great.      1\n",
       "4  I have to jiggle the plug to get it to line up...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "umich_data = pd.read_csv('training.txt', sep='\\t')\n",
    "umich_data.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [imdb_data, amazon_data, yelp_data, umich_data]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Very little music or anything to speak of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Not sure who was more lost - the flat characte...\n",
       "1      0  Attempting artiness with black & white and cle...\n",
       "2      0          Very little music or anything to speak of\n",
       "3      1  The best scene in the movie was when Gerardo i...\n",
       "4      0  The rest of the movie lacks art, charm, meanin..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9914 entries, 0 to 6916\n",
      "Data columns (total 2 columns):\n",
      "label    9914 non-null int64\n",
      "text     9914 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 232.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more_data = pd.read_csv('train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>demonstrating the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>is also good for the gander , some of which oc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>is also good for the gander , some of which oc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>is also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156030</th>\n",
       "      <td>a joke in the United States</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156032</th>\n",
       "      <td>The movie 's downfall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156033</th>\n",
       "      <td>is to substitute plot for personality .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156034</th>\n",
       "      <td>is to substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156035</th>\n",
       "      <td>to substitute plot for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156036</th>\n",
       "      <td>substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156037</th>\n",
       "      <td>substitute plot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156038</th>\n",
       "      <td>for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156040</th>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156041</th>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156042</th>\n",
       "      <td>is darkly atmospheric ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156043</th>\n",
       "      <td>is darkly atmospheric</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156044</th>\n",
       "      <td>with Herrmann quietly suggesting the sadness a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156045</th>\n",
       "      <td>Herrmann quietly suggesting the sadness and ob...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156046</th>\n",
       "      <td>Herrmann</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156047</th>\n",
       "      <td>quietly suggesting the sadness and obsession b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156048</th>\n",
       "      <td>suggesting the sadness and obsession beneath H...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156049</th>\n",
       "      <td>suggesting the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156050</th>\n",
       "      <td>the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156052</th>\n",
       "      <td>sadness and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156053</th>\n",
       "      <td>beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156054</th>\n",
       "      <td>Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrase  Sentiment\n",
       "0       A series of escapades demonstrating the adage ...          1\n",
       "1       A series of escapades demonstrating the adage ...          2\n",
       "2                                                A series          2\n",
       "3                                                       A          2\n",
       "4                                                  series          2\n",
       "5       of escapades demonstrating the adage that what...          2\n",
       "6                                                      of          2\n",
       "7       escapades demonstrating the adage that what is...          2\n",
       "8                                               escapades          2\n",
       "9       demonstrating the adage that what is good for ...          2\n",
       "10                                demonstrating the adage          2\n",
       "11                                          demonstrating          2\n",
       "12                                              the adage          2\n",
       "13                                                    the          2\n",
       "14                                                  adage          2\n",
       "15                        that what is good for the goose          2\n",
       "16                                                   that          2\n",
       "17                             what is good for the goose          2\n",
       "18                                                   what          2\n",
       "19                                  is good for the goose          2\n",
       "20                                                     is          2\n",
       "21                                     good for the goose          3\n",
       "22                                                   good          3\n",
       "23                                          for the goose          2\n",
       "24                                                    for          2\n",
       "25                                              the goose          2\n",
       "26                                                  goose          2\n",
       "27      is also good for the gander , some of which oc...          2\n",
       "28      is also good for the gander , some of which oc...          2\n",
       "29                                                is also          2\n",
       "...                                                   ...        ...\n",
       "156030                        a joke in the United States          2\n",
       "156031  The movie 's downfall is to substitute plot fo...          1\n",
       "156032                              The movie 's downfall          1\n",
       "156033            is to substitute plot for personality .          1\n",
       "156034              is to substitute plot for personality          1\n",
       "156035                 to substitute plot for personality          2\n",
       "156036                    substitute plot for personality          1\n",
       "156037                                    substitute plot          2\n",
       "156038                                    for personality          2\n",
       "156039  The film is darkly atmospheric , with Herrmann...          2\n",
       "156040  is darkly atmospheric , with Herrmann quietly ...          2\n",
       "156041  is darkly atmospheric , with Herrmann quietly ...          2\n",
       "156042                            is darkly atmospheric ,          2\n",
       "156043                              is darkly atmospheric          3\n",
       "156044  with Herrmann quietly suggesting the sadness a...          2\n",
       "156045  Herrmann quietly suggesting the sadness and ob...          2\n",
       "156046                                           Herrmann          2\n",
       "156047  quietly suggesting the sadness and obsession b...          1\n",
       "156048  suggesting the sadness and obsession beneath H...          2\n",
       "156049               suggesting the sadness and obsession          2\n",
       "156050                          the sadness and obsession          2\n",
       "156051                              sadness and obsession          1\n",
       "156052                                        sadness and          1\n",
       "156053        beneath Hearst 's forced avuncular chortles          2\n",
       "156054                Hearst 's forced avuncular chortles          2\n",
       "156055                                          Hearst 's          2\n",
       "156056                          forced avuncular chortles          1\n",
       "156057                                 avuncular chortles          3\n",
       "156058                                          avuncular          2\n",
       "156059                                           chortles          2\n",
       "\n",
       "[156060 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_data.drop(['PhraseId', 'SentenceId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(string):\n",
    "    return len(string)\n",
    "  \n",
    "    \n",
    "data['text length'] = data['text'].apply(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113aa00f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJKK/wVYNig6+p+tzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113aa0748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['text length'], kde=False, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "X = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.90      0.91      1324\n",
      "          1       0.92      0.93      0.93      1651\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import  TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer()),('tfidf', TfidfTransformer()), ('mlp', MLPClassifier(hidden_layer_sizes=(100,2)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92      1324\n",
      "          1       0.93      0.94      0.94      1651\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "more_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = more_data['Phrase']\n",
    "y = more_data['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_nb1 = Pipeline([('vectorizer', CountVectorizer()),('nb', MultinomialNB())])\n",
    "\n",
    "pipeline_nb1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline_nb1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['This was a great movie!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment(string):\n",
    "    if pipeline.predict([string]) == [1]:\n",
    "        return \"Positive review!\"\n",
    "    else:\n",
    "        return \"Negative review!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive review!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('Great!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('I really hated the pointless action sequences!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('That was a very unusual and strange choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('We purchased from Sears a new Kenmore Elite electric double-wall oven Model # 79048459 in December, 2016 for our remodeled kitchen. In all instances, when trying to broil chicken, beef, or fish in our top oven, the oven generated so much smoke and grease that our fire alarms (located about 20 feet away between two rooms) would go off. We contacted Sears, and their experienced technicians came to our home and essentially replaced all of the electrical components in our oven and the heating coil. After this was completed, we placed a 1 inch steak on a professional broiling pan in the top oven at 550 degrees, and lowered the rack position to 4 according to the Sears manual for this oven and in less than 4 minutes in the oven (without even opening the door of the oven) the smoke being blown out of the top of the oven was so dense that our fire alarms went off once again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive review!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('This was not a good experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('That was terrible!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('That was not that good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('Ordered 4 mouse pads from China. They never arrived. When I looked at the Amazon tracking it said it was delivered to my home in Wooster, Ohio. I then took the USPS tracking number and found that it was delivered to a different address in Pennsylvania!!! I contacted the seller and he never responded to me. When I looked on the Amazon site for a customer service number to call... There was NONE!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment(\"Thanks to a high concentration of sodium and magnesium in Dead Sea mud. this mask claims to draw out blackheads and blemishes like a magnet. With ingredients like kaolin and sunflower oils, we believe it. Amazon user Destinee Ray couldn't agree more. My blackheads were gone and my skin just looked brighter and also felt really soft. I didn't have any irritation or bad reaction, which I was worried about at first because I do have very sensitive skin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative review!'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment('My skin looked brighter and also felt really soft. That was really good!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using a Wide Variety of Emotion Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we performed sentiment analysis for the purpose of determining positive or negative reviews but here we will use sentiment analysis to classify tweets as representing one of thirteen different emotions. The dataset for this classification task is present in the text_emotion.csv file. The goal of this task is to create a function that takes a tweet as a string input and classifies this tweet, producing the classification (emotion) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the data from the csv file.\n",
    "emotion_data = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 4 columns):\n",
      "tweet_id     40000 non-null int64\n",
      "sentiment    40000 non-null object\n",
      "author       40000 non-null object\n",
      "content      40000 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "emotion_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = emotion_data['content']\n",
    "y = emotion_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train) # This is a computationally expensive task that may take a while. (Around 15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.00      0.00      0.00        34\n",
      "    boredom       0.02      0.02      0.02        50\n",
      "      empty       0.02      0.02      0.02       263\n",
      " enthusiasm       0.02      0.02      0.02       212\n",
      "        fun       0.12      0.05      0.07       529\n",
      "  happiness       0.26      0.30      0.27      1591\n",
      "       hate       0.15      0.14      0.15       395\n",
      "       love       0.25      0.28      0.26      1088\n",
      "    neutral       0.31      0.29      0.30      2622\n",
      "     relief       0.05      0.05      0.05       489\n",
      "    sadness       0.24      0.23      0.24      1616\n",
      "   surprise       0.09      0.11      0.10       628\n",
      "      worry       0.30      0.31      0.30      2483\n",
      "\n",
      "avg / total       0.24      0.24      0.24     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example we can see that even a complex MLP Classifier did pretty terrible. So another approach is to try the simpler Multinomial Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# Function for processing text\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_naive_bayes = Pipeline([('vectorizer', CountVectorizer()), ('nb', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=<function text_process at 0x11a57bbf8>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_naive_bayes.fit(X_train, y_train)  # Since this algorithm is simpler it takes less time to execute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline_naive_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.00      0.00      0.00        34\n",
      "    boredom       0.00      0.00      0.00        50\n",
      "      empty       0.00      0.00      0.00       263\n",
      " enthusiasm       0.00      0.00      0.00       212\n",
      "        fun       0.00      0.00      0.00       529\n",
      "  happiness       0.33      0.29      0.31      1591\n",
      "       hate       0.57      0.01      0.02       395\n",
      "       love       0.48      0.29      0.36      1088\n",
      "    neutral       0.32      0.33      0.32      2622\n",
      "     relief       0.00      0.00      0.00       489\n",
      "    sadness       0.30      0.11      0.16      1616\n",
      "   surprise       0.30      0.00      0.01       628\n",
      "      worry       0.27      0.72      0.39      2483\n",
      "\n",
      "avg / total       0.29      0.30      0.25     12000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are still not great so we may have to try something else again. For now, lets try a RandomForest Classifier and see if that produces anything better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_rfc = Pipeline([('vectorizer', CountVectorizer()), ('rfc', RandomForestClassifier(n_estimators = 200))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=<function text_process at 0x11a57bbf8>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocesso...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      anger       0.00      0.00      0.00        34\n",
      "    boredom       0.02      0.02      0.02        50\n",
      "      empty       0.02      0.02      0.02       263\n",
      " enthusiasm       0.02      0.02      0.02       212\n",
      "        fun       0.12      0.05      0.07       529\n",
      "  happiness       0.26      0.30      0.27      1591\n",
      "       hate       0.15      0.14      0.15       395\n",
      "       love       0.25      0.28      0.26      1088\n",
      "    neutral       0.31      0.29      0.30      2622\n",
      "     relief       0.05      0.05      0.05       489\n",
      "    sadness       0.24      0.23      0.24      1616\n",
      "   surprise       0.09      0.11      0.10       628\n",
      "      worry       0.30      0.31      0.30      2483\n",
      "\n",
      "avg / total       0.24      0.24      0.24     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = emotion_data[(emotion_data['sentiment'] == 'sadness') | (emotion_data['sentiment'] == 'happiness')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id sentiment       author  \\\n",
       "1  1956967666   sadness    wannamama   \n",
       "2  1956967696   sadness    coolfunky   \n",
       "6  1956968487   sadness     ShansBee   \n",
       "8  1956969035   sadness  nic0lepaula   \n",
       "9  1956969172   sadness   Ingenue_Em   \n",
       "\n",
       "                                             content  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "6  I should be sleep, but im not! thinking about ...  \n",
       "8            @charviray Charlene my love. I miss you  \n",
       "9         @kelcouch I'm sorry  at least it's Friday?  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10374 entries, 1 to 39998\n",
      "Data columns (total 4 columns):\n",
      "tweet_id     10374 non-null int64\n",
      "sentiment    10374 non-null object\n",
      "author       10374 non-null object\n",
      "content      10374 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 405.2+ KB\n"
     ]
    }
   ],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = new_data['content']\n",
    "y = new_data['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_naive_bayes.fit(X_train, y_train)  #Started at 5:22 ended at 5:28 approx 6 minutes run time with neural net\n",
    "                                    # RFC took about a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline_naive_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  happiness       0.82      0.77      0.79      1555\n",
      "    sadness       0.78      0.83      0.80      1558\n",
      "\n",
      "avg / total       0.80      0.80      0.80      3113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def happy_or_sad(string):\n",
    "    if pipeline_naive_bayes.predict([string]) == ['happiness']:\n",
    "        return 'Happy'\n",
    "    else: \n",
    "        return 'Sad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_or_sad('I am happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sad'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_or_sad('I do not like the rain!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sad'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_or_sad('Had to attend the funeral of a friend today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
